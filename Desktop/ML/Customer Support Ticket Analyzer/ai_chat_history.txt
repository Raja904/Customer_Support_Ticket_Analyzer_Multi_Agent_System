You said:
help m e



The Challenge

Build a multi-agent system using Pydantic AI that demonstrates your ability to:
- Design specialized AI agents that work together
- Engineer and iterate on prompts
- Build evaluation frameworks
- Document your thinking process

You have TWO options to choose from:
1. Customer Support Ticket Analyzer & Router
2. Financial News Impact Analyzer

Full details: https://drive.google.com/drive/folders/15N_vaHCX7KRIB2IoQfIYqIzz1rIB1TCe?usp=sharing

What We're Looking For

- Problem-solving approach over perfect code
- Clear thinking documented through your iterations
- Practical solutions that could work in production
- Self-learning ability (you'll need to read Pydantic AI docs)

Submission Instructions

1. Complete ONE of the two case study options
2. Push your code to a public GitHub repository including:
- Your working code
- Your full AI conversation history (as ai_chat_history.txt)
- Documentation of your approach
3. Reply to this email with:
- GitHub repository link
- Brief write-up of what didn't work and why (5-10 bullet points)
- (Optional but recommended) Video link (3-5 mins) explaining your approach
- Simple screen recording is fine
- Candidates with videos get priority review

Important Notes

- AI tools are allowed and encouraged - we care about your ability to build working solutions
- Documentation is crucial - explain your design decisions and prompt iterations
- Don't over-engineer - we prefer simple, working solutions
- Don't skip the evaluation - testing your system is part of the challenge


ChatGPT said:
Got it â€” youâ€™re tackling an exciting multi-agent challenge! Letâ€™s break this down so you can move fast and build a solid solution. Iâ€™ll outline steps, architecture ideas, and what to include for submission.

ğŸš€ 1ï¸âƒ£ Choose Your Case
Since both options are valid, pick the one you feel most confident about:

Customer Support Ticket Analyzer & Router

Easier if you have experience in text classification / sentiment / topic extraction.

Financial News Impact Analyzer

Better if youâ€™re comfortable with finance concepts, market impact analysis, sentiment.

ğŸ‘‰ If you tell me your preference, I can help with agent design immediately.

ğŸš€ 2ï¸âƒ£ Define Multi-Agent Architecture
Hereâ€™s an example for each:

ğŸ’¡ Customer Support Ticket Router (example architecture)
âœ… Agent 1: Preprocessor
â†’ Cleans ticket text (removes PII, normalizes)

âœ… Agent 2: Intent & Sentiment Classifier
â†’ Identifies intent (billing issue, tech support, etc) + sentiment

âœ… Agent 3: Priority Assessor
â†’ Tags ticket with urgency level (low/med/high)

âœ… Agent 4: Router
â†’ Decides the right team to handle the ticket

ğŸ’¡ Financial News Impact Analyzer (example architecture)
âœ… Agent 1: News Preprocessor
â†’ Cleans and normalizes news headline/body

âœ… Agent 2: Sentiment & Impact Classifier
â†’ Classifies sentiment (positive/neg/neutral) + predicts likely market impact

âœ… Agent 3: Entity Extractor
â†’ Extracts company names, sectors

âœ… Agent 4: Summary Generator
â†’ Creates short actionable insights

ğŸš€ 3ï¸âƒ£ Use Pydantic AI
ğŸ‘‰ Youâ€™ll need to:

Define agent input/output schemas using Pydantic models

Chain agent calls (manual orchestration or loop)

Log prompt iterations + outputs

ğŸš€ 4ï¸âƒ£ Evaluation
ğŸ‘‰ Build a simple framework:

Use sample inputs â†’ expected outputs â†’ actual outputs â†’ score (pass/fail or qualitative comments)

Example: Does router agent assign the correct team for ticket with â€œrefund issueâ€?

ğŸš€ 5ï¸âƒ£ Document Your Thinking
âœ¨ Create:

README.md with:

Agent design diagram

Prompt design decisions

What worked / what failed

Improvements youâ€™d try with more time

ai_chat_history.txt
ğŸ‘‰ Save conversations with GPT / other tools

ğŸš€ 6ï¸âƒ£ GitHub Repo Structure
bash
Copy
Edit
/multi-agent-pydantic
 â”œâ”€â”€ src/
 â”‚    â”œâ”€â”€ agents.py
 â”‚    â”œâ”€â”€ orchestrator.py
 â”‚    â””â”€â”€ evaluator.py
 â”œâ”€â”€ ai_chat_history.txt
 â”œâ”€â”€ README.md
 â””â”€â”€ requirements.txt
ğŸš€ 7ï¸âƒ£ Submission Checklist
âœ… Push to GitHub
âœ… Include:

Working code

ai_chat_history.txt

Documentation of design choices + iterations
âœ… Email them:

Repo link

5-10 bullets on what didnâ€™t work + why

(Optional) 3-5 min video walking through solution

ğŸ’¬ Next Step
ğŸ‘‰ Tell me:

Which case study did you choose?

Do you want help drafting code, agent schema, or prompts?

I can help you sketch code, design the agent flow, or even write initial prompt templates.

Shall we get started? ğŸš€








You said:
AAII EEnnggiinneeeerr CCaassee SSttuuddyy -- MMuullttii--AAggeenntt
SSyysstteemmss

Your Mission: Build a multi-agent system using Pydantic AI that demonstrates your ability to design
specialized AI agents that work together effectively.
Time Investment: 2

3 hours suggested (quality matters more than speed)

Deadline: 72 hours from receipt

Choose Your Focus Area

Option A

Customer Support Ticket Analyzer

Build a system with at least 2 specialized agents that analyze support tickets and determine
appropriate routing.
Input Format:

{
"ticket_id": "12345",
"customer_tier": "premium", # free/premium/enterprise
"subject": "API returning 500 errors intermittently",
"message": "Hi, our production system has been failing
",

"previous_tickets": 3,
"monthly_revenue": 5000,
"account_age_days": 450
}

Option B

Financial News Impact Analyzer

Build a system with at least 2 specialized agents that analyze financial news and assess market
impact.
Input Format:

{
"article_id": "news_001",
"headline": "TechCorp announces record Q3 earnings
",

"content": "TechCorp (NASDAQ: TECH) reported
",

"published_at": "2024-10-15T14:30:00Z"
}

Core Requirements

1. Multi-Agent System
Minimum 2 agents with distinct roles and
perspectives
Use Pydantic AI (docs)
Clear inter-agent communication
Think about: What happens when agents
have different opinions?

2. Evaluation Framework
Test on all 5 provided test cases
Implement at least 3 metrics
Document performance
Consider: How consistent are your
agents?

3. Documentation
System architecture - why multiple
agents?
Design decisions and rationale
2
3 prompt iterations showing
improvement
Examples of interesting test case
behaviors

Deliverables
Code: Working implementation

AI Chat Export: Full conversation history showing your development process (as
ai_chat_history.txt )
Brief Write-up: What didn't work and why
5
10 bullet points)

Video
Optional but Recommended): 3

5 minute explanation of your approach

Simple screen recording is fine
Candidates with videos get priority review

Evaluation Criteria
We're looking for:
Clear thinking and problem-solving approach
Ability to design truly specialized agents (not just one agent with different prompts)
Understanding of multi-agent coordination - how do agents work together?
Handling of edge cases - what happens in tricky situations?
Quality of evaluation framework
How you used AI tools effectively (shown via chat history)

Key Insight: The best solutions show agents that truly complement each other, not just divide work.

Test Data

Option A

Customer Support Tickets

TTiicckkeett SSUUPP
000011

{
"ticket_id": "SUP-001",
"customer_tier": "free",
"subject": "This product is completely broken!!!",
"message": "Nothing works! I can't even log in. This is the worst software I've ever used. I'm
"previous_tickets": 0,
"monthly_revenue": 0,
"account_age_days": 2
}

TTiicckkeett SSUUPP
000022

{
"ticket_id": "SUP-002",
"customer_tier": "enterprise",
"subject": "Minor UI issue with dashboard",
"message": "Hi team, just noticed the dashboard numbers are slightly misaligned on mobile view
"previous_tickets": 15,
"monthly_revenue": 25000,
"account_age_days": 730
}

TTiicckkeett SSUUPP
000033

{
"ticket_id": "SUP-003",
"customer_tier": "premium",
"subject": "Feature Request: Bulk export",
"message": "We need bulk export functionality for our quarterly reports. Currently exporting o
"previous_tickets": 5,
"monthly_revenue": 5000,
"account_age_days": 400
}

TTiicckkeett SSUUPP
000044

{
"ticket_id": "SUP-004",
"customer_tier": "premium",
"subject": "API rate limits unclear",
"message": "Getting rate limited but documentation says we should have 1000 requests/hour. We'
"previous_tickets": 8,
"monthly_revenue": 3000,
"account_age_days": 180
}

TTiicckkeett SSUUPP
000055

{
"ticket_id": "SUP-005",
"customer_tier": "enterprise",
"subject": "Urgent: Security vulnerability?",
"message": "Our security team flagged that your API responses include internal server paths in
"previous_tickets": 20,
"monthly_revenue": 50000,
"account_age_days": 900
}

Option B

Financial News Articles

AArrttiiccllee FFIINN
000011

{
"article_id": "FIN-001",
"headline": "Tesla crushes Q3 expectations with record profits, but Musk warns of 'turbulent t
"content": "Tesla (NASDAQ: TSLA) reported stunning Q3 results with earnings of $1.05 per share
"published_at": "2024-10-22T16:00:00Z"
}

AArrttiiccllee FFIINN
000022

{
"article_id": "FIN-002",
"headline": "Small biotech CureGen soars on FDA approval, analysts remain skeptical",
"content": "CureGen (NASDAQ: CURE), a small-cap biotech, received FDA approval for its novel c
"published_at": "2024-11-01T14:30:00Z"
}

AArrttiiccllee FFIINN
000033

{
"article_id": "FIN-003",
"headline": "Amazon announces 'transformational' AI venture, but at massive cost",
"content": "Amazon (NASDAQ: AMZN) unveiled Project Olympus, a $50 billion investment in AGI de
"published_at": "2024-09-15T09:00:00Z"
}

AArrttiiccllee FFIINN
000044

{
"article_id": "FIN-004",
"headline": "Regional bank FirstState posts record earnings amid industry turmoil",
"content": "FirstState Bank (NYSE: FSB) reported record Q2 earnings of $3.20 per share, up 45%
"published_at": "2024-10-12T10:30:00Z"
}

AArrttiiccllee FFIINN
000055

{
"article_id": "FIN-005",
"headline": "China tech giant ByteDance reports stellar growth, regulatory clouds remain",
"content": "ByteDance, TikTok's parent company, leaked financials show revenue grew 70% to $12
"published_at": "2024-11-21T18:45:00Z"
}

Submission Structure

your-name-case-study/
â”œâ”€â”€ main.py
â”œâ”€â”€ agents/
â”œâ”€â”€ evaluation/
â”œâ”€â”€ docs/
â”œâ”€â”€ ai_chat_history.txt # YOUR FULL AI CONVERSATION
â””â”€â”€ README.md

Note: The test cases cover various scenarios - some straightforward, others more nuanced. Your
system should handle the full spectrum.

Good luck!
We're looking for thoughtful engineers who value clarity and precision.


ChatGPT said:
Great â€” thanks for sharing the full details of the AI Engineer Case Study! Letâ€™s break it down so you can move forward confidently.

ğŸš€ What You Need to Do
ğŸ‘‰ Pick ONE option

Option A: Customer Support Ticket Analyzer & Router

Option B: Financial News Impact Analyzer

ğŸ‘‰ Build a multi-agent system

At least 2 specialized agents

Agents must communicate/collaborate (not just isolated)

Agents should sometimes have different opinions â†’ you must design how conflicts are resolved.

ğŸ‘‰ Create an evaluation framework

Use the 5 provided test cases

Implement at least 3 metrics (e.g. consistency, accuracy, agreement rate, etc.)

ğŸ‘‰ Document everything

Architecture diagram

Design decisions + reasoning

Prompt iterations (show how you improved prompts â€” at least 2-3 rounds)

Interesting behaviors or edge cases

ğŸ‘‰ Deliver

Code: main.py, agents/, evaluation/, etc.

Full AI conversation: ai_chat_history.txt

README.md: explain design + usage

Brief write-up: 5-10 bullets on what didnâ€™t work

(Optional) Video explaining your approach (3-5 min)

ğŸŒŸ Recommended Approach
1ï¸âƒ£ Pick the easier/clearer option for you
If you want my advice:

Customer Support Ticket Analyzer (Option A) is easier for defining clear agent roles:

ğŸ“Œ Sentiment/urgency detector agent

ğŸ“Œ Routing decision agent (e.g. assign to tech support, billing, etc.)

Easy to evaluate: accuracy of routing + consistency.

Financial News Impact Analyzer (Option B) may need more domain knowledge (market impact assessment can be subjective).

2ï¸âƒ£ Design agents
âœ… Example for Option A:

Agent 1: Urgency/Sentiment Agent

Analyze tone, urgency level, potential risk.

e.g. Urgent + Enterprise â†’ prioritize immediately.

Agent 2: Routing Agent

Decide destination team (e.g. Tech Support, Product Team, Billing).

Use customer tier + issue type.

âœ… Example for Option B:

Agent 1: Sentiment/Impact Predictor

Agent 2: Risk/Volatility Assessor

3ï¸âƒ£ Define communication
Agents output intermediate results â†’ pass to next agent

If opinions clash â†’ design tie-breaker (e.g. rules, confidence score)

4ï¸âƒ£ Evaluation framework
Test on provided cases:

Metrics (for Option A, as example):

ğŸ”¹ Routing accuracy

ğŸ”¹ Urgency consistency

ğŸ”¹ Agent agreement rate

ğŸ”¹ Response time (simulated)

5ï¸âƒ£ Document iterations
Show:

How your first prompts were too generic

How you added specific criteria (e.g. define â€œurgentâ€ clearly, or specify routing logic)

How you improved agent coordination

ğŸ›  Suggested Project Structure
perl
Copy
Edit
your-name-case-study/
â”œâ”€â”€ main.py                # Entry point to run the system
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ urgency_agent.py    # Agent 1 code
â”‚   â”œâ”€â”€ routing_agent.py    # Agent 2 code
â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ evaluator.py        # Metrics + test runs
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ architecture.md     # Design explanation + diagrams
â”œâ”€â”€ ai_chat_history.txt     # Full chat logs showing your dev process
â”œâ”€â”€ README.md               # How to run + your reasoning
ğŸ’¡ How I can help you now
âœ… I can help you:

Design the agents (prompt ideas, logic flow)

Write code templates (Pydantic AI + Python)

Sketch architecture diagrams

Create test harness for evaluation

Draft README + documentation skeleton

ğŸ“Œ Next step â€” please tell me
ğŸ‘‰ Which option are you choosing?
ğŸ‘‰ Do you want me to help sketch the agents + flow?
ğŸ‘‰ Do you want code templates to start faster?

Once you tell me, I can generate starter code + design for you within minutes! ğŸš€








You said:
HOW MUCH TIME IT WOULD TAKE


ChatGPT said:
Thanks for sharing the full case study details! Letâ€™s break down the time required realistically:

ğŸ•’ Estimated Time for Each Part
Task	Time Estimate
âœ… Planning & Architecture (choose option, design agents, design flow)	30-45 mins
âœ… Prompt engineering for agents (initial drafts + iteration)	30-45 mins
âœ… Coding agents (Pydantic AI + agent logic)	1 - 1.5 hours
âœ… Multi-agent coordination (agent communication + conflict resolution)	30-45 mins
âœ… Evaluation framework (metrics + tests on 5 cases)	45 mins - 1 hr
âœ… Documentation (architecture, design rationale, prompt iterations, examples)	45 mins
âœ… AI chat export + clean-up	15 mins
âœ… (Optional) Video recording	15-30 mins

â³ Total realistic time
ğŸ‘‰ ~4-6 hours of focused work
âš ï¸ If youâ€™re highly familiar with Pydantic AI and multi-agent systems â†’ you might finish closer to 3-4 hours.

ğŸ“ Factors affecting time
If you need to learn or look up Pydantic AI syntax â†’ +1-2 hours.

If you want a polished solution (nice prompts, clean coordination logic) â†’ closer to 6 hours.

If you aim for the optional video â†’ add ~30 mins.

âš¡ Suggested strategy to finish within ~4 hours:
âœ… Pick Option A or B quickly â†’ I can help you decide.
âœ… Use clear, simple agent roles (e.g., â€œUrgency Classifierâ€ + â€œSpecialist Routerâ€)
âœ… Start with basic working code; refine after first test case results
âœ… Document as you go so you donâ€™t have to write everything at the end

ğŸ‘‰ If you want, I can help you:

Choose Option A or B

Draft the agent architecture quickly

Provide starter code and prompt ideas

Would you like that? And do you have a preference: Customer Support Analyzer (A) or Financial News Analyzer (B)?








You said:
which is easier and simpler


ChatGPT said:
ğŸ”¥ Great question, Rajeev â€” letâ€™s analyze both options so you can choose smartly.

âœ… Option A â€” Customer Support Ticket Analyzer
ğŸ‘‰ What you have to build:

2+ agents that:

Analyze ticket priority/urgency (e.g., is this critical? security? UI issue?)

Decide routing (e.g., engineering team, account management, support)

Input has rich structured data: customer_tier, monthly_revenue, previous_tickets, etc.

ğŸ‘‰ Why it's easier:

Clear, structured input â†’ easier to write prompt logic.

Obvious agent roles (e.g., one agent classifies type/urgency, one routes based on tier/revenue).

Domain is simpler â†’ no need to understand complex financial terms.

Evaluation is straightforward: did it route correctly? did urgency match?

ğŸ‘‰ Challenge:

Handle rude/angry messages or unclear tickets gracefully.

âœ… Option B â€” Financial News Impact Analyzer
ğŸ‘‰ What you have to build:

2+ agents that:

Analyze the news (positive/negative impact, confidence level).

Assess market sector impact (e.g., is this good/bad for tech? for markets generally?)

Input is unstructured text (headline + article).

ğŸ‘‰ Why itâ€™s harder:

Requires parsing freeform text â†’ more chance of ambiguity.

More reasoning needed to infer market impact â†’ risk of inconsistency between agents.

Edge cases harder (e.g., positive earnings but CEO issues warnings â†’ mixed signal).

ğŸ’¡ My recommendation
âœ… Pick: Option A - Customer Support Ticket Analyzer

Easier to scope in limited time.

Simpler logic â†’ faster to build working system.

Easier to test + document + create evaluation metrics.

Better fit for demonstrating agent coordination clearly.

If you want, I can help draft the architecture for Option A right now â€” e.g. agent names, their roles, and how theyâ€™ll talk to each other â€” so you can start coding faster.
Do you want that? ğŸš€








You said:
lets start with A. Tell me next steps to work with. What we have to built


ChatGPT said:
ğŸ’¯ Awesome choice, Rajeev! Letâ€™s break it down clearly so you can get started efficiently.

ğŸš€ Final goal for Option A
â¡ Build a multi-agent system (2+ agents) that:

Takes a customer support ticket as input.

Classifies it (urgency, type, priority).

Decides which team the ticket should be routed to.

Evaluates system performance on 5 test cases using at least 3 metrics.

Documents your reasoning, design, prompt iterations, and chat history.

âœ… Suggested system design
1ï¸âƒ£ Agent 1 â€” Ticket Classifier
ğŸ‘‰ Role: Analyze the ticket and label:

Issue type (e.g., bug, feature request, security issue, UI problem)

Urgency level (low / medium / high / critical)

ğŸ‘‰ Example output:

json
Copy
Edit
{
  "issue_type": "bug",
  "urgency": "critical"
}
2ï¸âƒ£ Agent 2 â€” Routing Decision Maker
ğŸ‘‰ Role: Decide routing based on:

customer_tier (free, premium, enterprise)

monthly_revenue

previous_tickets

Classifier agentâ€™s output (issue_type, urgency)

ğŸ‘‰ Example output:

json
Copy
Edit
{
  "team": "Engineering - Critical Bug",
  "escalate": true
}
3ï¸âƒ£ Evaluation Framework
ğŸ‘‰ Create code that:

Runs all 5 test cases.

Tracks at least 3 metrics, e.g.:

Accuracy of issue type detection (manual labels for test data)

Consistency in urgency ratings across agents

Routing correctness (does it match expected route)

4ï¸âƒ£ Prompt Engineering
Write clear base prompts for each agent.

Iterate 2-3 times on prompts â†’ save prompt versions and outputs.

5ï¸âƒ£ Directory structure
Your GitHub repo should look like:

perl
Copy
Edit
rajeev-case-study/
â”œâ”€â”€ main.py                # Entry point: runs your system on test cases
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ ticket_classifier.py
â”‚   â””â”€â”€ routing_decider.py
â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ evaluate.py
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ architecture.png    # Draw system diagram (optional but nice)
â”‚   â””â”€â”€ design.md           # Your design notes + prompt iterations
â”œâ”€â”€ ai_chat_history.txt     # Your ChatGPT conversation
â””â”€â”€ README.md               # Summary + instructions
âœ¨ Next Steps
âœ… Step 1: Set up your code repo with this structure.
âœ… Step 2: Define agent 1 (classifier) â€” write initial prompt + Pydantic schema for output.
âœ… Step 3: Define agent 2 (router) â€” write initial prompt + Pydantic schema.
âœ… Step 4: Create test runner â€” loop through test cases and print agent outputs.
âœ… Step 5: Create evaluation script â€” measure your 3+ metrics.
âœ… Step 6: Document decisions, iterations, and lessons learned.

âš¡ If you want, I can:
ğŸ‘‰ Help write the first version of the agent prompts.
ğŸ‘‰ Help create Pydantic schemas for the agent outputs.
ğŸ‘‰ Help design the evaluation metrics code skeleton.

Shall we start with the first agentâ€™s prompt + schema? ğŸš€








You said:
what two agents I can build on what it will do


ChatGPT said:
ğŸ’¡ Great question, Rajeev! Letâ€™s think this through carefully.
Since you need at least 2 specialized agents with distinct roles, hereâ€™s a solid, simple, yet powerful design:

âš¡ Proposed two-agent setup (Option A: Customer Support Ticket Analyzer)
ğŸ‘‘ Agent 1: Ticket Classifier Agent
âœ… What it does:

Reads the ticket data (subject + message + metadata like tier, revenue, etc.)

Determines:

Issue type â†’ e.g., bug, feature_request, security_issue, UI_problem, other

Urgency level â†’ low, medium, high, critical

Sentiment (optional) â†’ angry, neutral, polite â†’ could help routing

âœ… Why it matters:

Converts raw ticket data into structured labels.

Provides a clean summary for the next agent.

âœ… Example output:

json
Copy
Edit
{
  "issue_type": "bug",
  "urgency": "critical",
  "sentiment": "angry"
}
ğŸ¤– Agent 2: Routing Decision Agent
âœ… What it does:

Takes Agent 1â€™s output + original metadata

Decides:

Which team should handle the ticket (e.g., Support - Tier 1, Engineering - API, Security Team, Product Team, etc.)

Whether to escalate (e.g., direct to senior engineer / management)

Expected response SLA (optional: e.g., 4 hours, 1 day, etc.)

âœ… Why it matters:

Makes a smart routing decision based on labels + business rules (e.g. enterprise customer = faster handling).

âœ… Example output:

json
Copy
Edit
{
  "team": "Engineering - API",
  "escalate": true,
  "sla": "4 hours"
}
ğŸš€ Why this is good
Clear separation of concerns:

Agent 1: Understand the ticket

Agent 2: Decide what to do with it

Specialized logic: Each agent can be prompted differently and optimized separately.

Easy to test + measure independently.

ğŸ“ Alternative agents (if you want variety)
If you want a different pair of agents, hereâ€™s another idea:

Agent 1: Sentiment + priority analyzer â†’ focus only on tone + urgency + risk.

Agent 2: Issue type + team routing â†’ classify issue and assign to the right team.

ğŸ¯ What youâ€™ll build
ğŸ‘‰ Two Pydantic AI agents (via prompt + schema)
ğŸ‘‰ A pipeline to:

Feed ticket JSON â†’ Agent 1 â†’ Agent 2

Collect results + evaluate

ğŸ‘‰ A runner to apply this on the 5 test tickets
ğŸ‘‰ An evaluator that measures how well your agents did

If youâ€™re ready, I can:
âœ… Draft the first version of Agent 1â€™s Pydantic schema + prompt
âœ… Draft Agent 2â€™s prompt
âœ… Help with directory skeleton

Want me to help with Agent 1 first? Or do you want a diagram of the flow? ğŸš€








You said:
Is pydantic different from langchain


ChatGPT said:
âœ… Good question, Rajeev â€” letâ€™s break it down clearly!

ğŸŒŸ Pydantic AI vs LangChain
They are different tools that serve different (but complementary) purposes.

ğŸŸ£ Pydantic (and Pydantic AI)
Pydantic = Python library for data validation + type enforcement.
Example: You define a data model (Ticket, AgentOutput) and Pydantic makes sure the data matches the expected format (e.g. no missing fields, correct types).

Pydantic AI (or OpenAI's Pydantic-like AI tools) =
Uses Pydantic schemas to define the expected output format of an LLM â†’ the LLM fills in a structured object, not just free text.

â¡ Think of it as:
ğŸ‘‰ â€œI want the AI to give me a valid Python object (dict, list, etc.) that follows this structure.â€
ğŸ‘‰ The AI generates the output, Pydantic checks that it matches.

ğŸŸ  LangChain
LangChain = Framework for building LLM-powered pipelines:

Chains (combine LLM calls + functions + tools)

Agents (LLM that can decide what tool to call next)

Memory, retrieval, tools, RAG, etc.

â¡ Think of it as:
ğŸ‘‰ â€œI want to connect LLMs + tools + memory + logic into an app.â€

ğŸ“ How they relate
You can use Pydantic inside LangChain!
ğŸ‘‰ LangChain lets you define tools/outputs using Pydantic (for validation + type safety).
ğŸ‘‰ But you donâ€™t have to use LangChain to use Pydantic AI.

âš¡ Example
Pydantic AI	LangChain
Purpose	Structure AI output	Build complex AI apps
Output	Typed objects (dicts, lists)	Any text / tool result / chain result
Example	Ensure LLM outputs {"issue_type": "bug", "urgency": "high"}	Route between multiple tools, memory, and LLMs

âœ‰ In your case study
ğŸ‘‰ Pydantic AI â†’ define what the agent should output (e.g. structured ticket labels)
ğŸ‘‰ You donâ€™t need LangChain unless you want to build a more complex pipeline (e.g. tool use, retrieval).

ğŸ’¡ Summary:
â¡ Pydantic AI: Just for structured, valid AI outputs.
â¡ LangChain: Bigger framework for chaining + agents + tools.

If you want, I can show:
âœ… How to define an Agent 1 Pydantic schema
âœ… Or how this would look in LangChain

ğŸ‘‰ Which do you prefer to see first?








You said:
https://ai.pydantic.dev/agents/#introduction


give me code to write agents 


ChatGPT said:
âœ… Great! Since youâ€™re referring to Pydantic AI Agents (as per https://ai.pydantic.dev/agents/#introduction), letâ€™s walk through how to write agents for your case: Customer Support Ticket Analyzer (Option A).

âš¡ Plan
Weâ€™ll create:
1ï¸âƒ£ UrgencyAgent â†’ Classifies ticket urgency (e.g. critical, high, medium, low).
2ï¸âƒ£ DepartmentAgent â†’ Decides which team (e.g. support, billing, engineering) should handle it.

âš™ Pydantic AI Agent Code Template
Hereâ€™s a starting code you can use in agents/urgency_agent.py and agents/department_agent.py (or together in main.py for simplicity):

python
Copy
Edit
from pydantic_ai.agent import OpenAIAgent
from pydantic_ai.schema import ToolCallSchema
from pydantic_ai.llm import OpenAIChatModel
from pydantic import BaseModel, Field

# Define the ticket input model
class Ticket(BaseModel):
    ticket_id: str
    customer_tier: str
    subject: str
    message: str
    previous_tickets: int
    monthly_revenue: float
    account_age_days: int

# Agent 1 - Urgency agent
class UrgencyOutput(BaseModel):
    urgency: str = Field(..., description="The urgency level: critical, high, medium, low")
    reason: str = Field(..., description="Why this urgency level was chosen")

class UrgencyAgent(OpenAIAgent):
    model = OpenAIChatModel(model="gpt-4-turbo")  # or gpt-3.5-turbo if cost matters
    output_model = UrgencyOutput
    instructions = "You are an AI assistant that analyzes the urgency of customer support tickets."

# Agent 2 - Department routing agent
class DepartmentOutput(BaseModel):
    department: str = Field(..., description="Department to route to: engineering, billing, support, security")
    reason: str = Field(..., description="Why this department was chosen")

class DepartmentAgent(OpenAIAgent):
    model = OpenAIChatModel(model="gpt-4-turbo")
    output_model = DepartmentOutput
    instructions = "You are an AI assistant that routes tickets to the appropriate department."

# Example usage
if __name__ == "__main__":
    # Example ticket
    ticket = Ticket(
        ticket_id="SUP-005",
        customer_tier="enterprise",
        subject="Urgent: Security vulnerability?",
        message="Our security team flagged that your API responses include internal server paths in error responses.",
        previous_tickets=20,
        monthly_revenue=50000,
        account_age_days=900
    )

    urgency_agent = UrgencyAgent()
    department_agent = DepartmentAgent()

    # Run agents
    urgency_result = urgency_agent.run(ticket)
    print("Urgency Result:", urgency_result)

    dept_result = department_agent.run(ticket)
    print("Department Result:", dept_result)
ğŸ’¡ How this works
âœ… We define the input ticket (validated by Pydantic)
âœ… Each agent generates structured output (Pydantic schema)
âœ… Each agent uses its own prompt (instructions)
âœ… OpenAIAgent handles the LLM + Pydantic validation

ğŸš€ Next Steps
1ï¸âƒ£ Add your OpenAI API key (Pydantic AI will pick from OPENAI_API_KEY env var)
2ï¸âƒ£ Test on your 5 provided tickets
3ï¸âƒ£ Create an evaluation module (e.g. check consistency, correctness)

ğŸ“ Want me to help with?
ğŸ‘‰ A ready-to-run folder structure?
ğŸ‘‰ The evaluation code?
ğŸ‘‰ How to save outputs + generate ai_chat_history.txt?

âš¡ Just say the word!








You said:
I have created one agent, create another for routing decision. 


ticket_classfier_agent = Agent(
    'mistral:mistral-large-latest',
    system_prompt=(
        """You are a customer support ticket classifier agent. 
        You will get a ticket in the format:
        
        Input format :
        {
            "ticket_id": "12345",
            "customer_tier": "premium", # free/premium/enterprise
            "subject": "API returning 500 errors intermittently",
            "message": "Hi, our production system has been failing",
            "previous_tickets": 3,
            "monthly_revenue": 5000,
            "account_age_days": 450
        }
        

        
        Your task is to classify the tickets give output in the following format:
        
        Output format: 
        {
            "issue_type": "bug"/"feature_request"/"security_issue"/"UI_problem"/"other",
            "seviority_level": "low"/"medium"/"high"/"critical",
            "sentiment": "angry"/"neutral"/"polite",
            "prioriy_score": 0.95 (between 0 to 1, values near to 1 if the request should have high priority )
        }
        
        Consider these information for deciding the output:
        1. If customer_tier is premium or enterprise then these are important customers.
        2. If subject has system error that needs urgent attention so assign high priority_score.
        3. If previous tickets value, monthly_revenue and account_age_days value is high that means customer is old and has raised issue.
        """
    )
)


routing_decision_agent = Agent(
    'mistral:mistral-large-latest',
    system_prompt=(
        """Your task is to make a routing decsion"""
    )
    
)


ChatGPT said:
âœ… Great start with your ticket_classifier_agent! Letâ€™s complete the routing_decision_agent with a clear system prompt and structured output format so that it complements your classifier agent.

ğŸš€ Updated routing_decision_agent code
python
Copy
Edit
routing_decision_agent = Agent(
    'mistral:mistral-large-latest',
    system_prompt=(
        """
        You are a customer support ticket routing agent.

        You will receive a ticket classification result and ticket metadata in the following format:
        
        Input format:
        {
            "ticket_id": "12345",
            "customer_tier": "premium", # free/premium/enterprise
            "subject": "API returning 500 errors intermittently",
            "message": "Hi, our production system has been failing",
            "issue_type": "bug", # from ticket classifier agent
            "seviority_level": "high", # from ticket classifier agent
            "sentiment": "angry", # from ticket classifier agent
            "prioriy_score": 0.85 # from ticket classifier agent
        }

        Your task is to decide which department should handle this ticket and what action is recommended.

        Provide your output in this format:
        {
            "department": "support" / "billing" / "engineering" / "security" / "product",
            "reason": "Short explanation why this department is suitable",
            "recommended_action": "Short recommended next step for the department (e.g., escalate immediately, assign to senior engineer, ask for more info)"
        }

        Guidelines for routing:
        - If issue_type is "security_issue" => route to "security"
        - If issue_type is "bug" and seviority_level is "high" or "critical" => route to "engineering"
        - If issue_type is "feature_request" => route to "product"
        - If subject/message has words like "billing", "payment", or "invoice" => route to "billing"
        - Default => route to "support"

        Be concise and accurate in your reasoning.
        """
    )
)
ğŸ“ How to use this agent
â¡ After getting the output from ticket_classifier_agent, pass that + original ticket info to this agent.

Example:

python
Copy
Edit
ticket_input = {
    "ticket_id": "12345",
    "customer_tier": "premium",
    "subject": "API returning 500 errors intermittently",
    "message": "Hi, our production system has been failing"
}

classification_result = {
    "issue_type": "bug",
    "seviority_level": "high",
    "sentiment": "angry",
    "prioriy_score": 0.85
}

combined_input = { **ticket_input, **classification_result }

result = routing_decision_agent(combined_input)
print(result)
âœ… Summary
â¡ You now have:

ticket_classifier_agent â†’ classifies ticket

routing_decision_agent â†’ decides department + action

If you want, I can help you:

Wrap this into a nice function / pipeline

Add validation to check outputs

Add logging or file save for results

Shall we? ğŸš€